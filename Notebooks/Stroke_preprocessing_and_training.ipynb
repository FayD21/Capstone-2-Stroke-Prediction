{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Pre-Processing and Training Data<a id='4_Pre-Processing_and_Training_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Introduction<a id='4.2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "In this notebook you'll start to build machine learning models. Before even starting with learning a machine learning model, however, start by considering how useful the mean value is as a predictor. This is more than just a pedagogical device. You never want to go to stakeholders with a machine learning model only to have the CEO point out that it performs worse than just guessing the average! Your first model is a baseline performance comparitor for any subsequent model. You then build up the process of efficiently and robustly creating and assessing models against it. The development we lay out may be little slower than in the real world, but this step of the capstone is definitely more than just instructional. It is good practice to build up an understanding that the machine learning pipelines you build work as expected. You can validate steps with your own functions for checking expected equivalence between, say, pandas and sklearn implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Imports<a id='4.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "#from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load Data<a id='4.4_Load_Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>67.00</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>80.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever_married</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <td>228.69</td>\n",
       "      <td>202.210000</td>\n",
       "      <td>105.92</td>\n",
       "      <td>171.23</td>\n",
       "      <td>174.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>36.60</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>32.50</td>\n",
       "      <td>34.40</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residence_type</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0           1       2       3       4\n",
       "gender               1.00    0.000000    1.00    0.00    0.00\n",
       "age                 67.00   61.000000   80.00   49.00   79.00\n",
       "hypertension         0.00    0.000000    0.00    0.00    1.00\n",
       "heart_disease        1.00    0.000000    1.00    0.00    0.00\n",
       "ever_married         1.00    1.000000    1.00    1.00    1.00\n",
       "avg_glucose_level  228.69  202.210000  105.92  171.23  174.12\n",
       "bmi                 36.60   28.893237   32.50   34.40   24.00\n",
       "smoking_status       1.00    0.000000    0.00    1.00    0.00\n",
       "stroke               1.00    1.000000    1.00    1.00    1.00\n",
       "residence_type       1.00    0.000000    0.00    1.00    0.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_data = pd.read_csv('../data/stroke_data_cleaned.csv')\n",
    "stroke_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5109, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train/Test Split - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What partition sizes would you have with a 70/30 train/test split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576.2999999999997, 1532.7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stroke_data) * .7, len(stroke_data) * .3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try a basic Logistic Regression:\n",
    "\n",
    "* Split the data into a training and test (hold-out) set\n",
    "* Train on the training set, and test for accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>residence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.189791</td>\n",
       "      <td>1.051242</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>4.184599</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>2.706450</td>\n",
       "      <td>1.001041</td>\n",
       "      <td>1.433107</td>\n",
       "      <td>0.983884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>0.785889</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>2.121652</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.697785</td>\n",
       "      <td>-1.016380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.189791</td>\n",
       "      <td>1.626174</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>4.184599</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>-0.004867</td>\n",
       "      <td>0.468399</td>\n",
       "      <td>-0.697785</td>\n",
       "      <td>-1.016380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>0.255182</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>1.437473</td>\n",
       "      <td>0.715233</td>\n",
       "      <td>1.433107</td>\n",
       "      <td>0.983884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>1.581949</td>\n",
       "      <td>3.042866</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>1.501297</td>\n",
       "      <td>-0.635858</td>\n",
       "      <td>-0.697785</td>\n",
       "      <td>-1.016380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender       age  hypertension  heart_disease  ever_married  \\\n",
       "0  1.189791  1.051242     -0.328637       4.184599      0.723678   \n",
       "1 -0.840484  0.785889     -0.328637      -0.238972      0.723678   \n",
       "2  1.189791  1.626174     -0.328637       4.184599      0.723678   \n",
       "3 -0.840484  0.255182     -0.328637      -0.238972      0.723678   \n",
       "4 -0.840484  1.581949      3.042866      -0.238972      0.723678   \n",
       "\n",
       "   avg_glucose_level       bmi  smoking_status  residence_type  \n",
       "0           2.706450  1.001041        1.433107        0.983884  \n",
       "1           2.121652 -0.000165       -0.697785       -1.016380  \n",
       "2          -0.004867  0.468399       -0.697785       -1.016380  \n",
       "3           1.437473  0.715233        1.433107        0.983884  \n",
       "4           1.501297 -0.635858       -0.697785       -1.016380  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the data into a training and test set\n",
    "X = stroke_data.drop('stroke', axis=1)\n",
    "y = stroke_data[['stroke']]\n",
    "\n",
    "#Applying Standardization using StandardScaler()\n",
    "columns = X.columns\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std = pd.DataFrame(X_std, columns=columns)\n",
    "X_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split for standardized features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.3, \n",
    "                                                    random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the shape, X-train, y_train head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3576, 9), (1533, 9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>residence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.540878</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>-1.123449</td>\n",
       "      <td>0.468399</td>\n",
       "      <td>1.433107</td>\n",
       "      <td>-1.016380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>1.537723</td>\n",
       "      <td>3.042866</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>1.881372</td>\n",
       "      <td>-0.570902</td>\n",
       "      <td>-0.697785</td>\n",
       "      <td>0.983884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>1.189791</td>\n",
       "      <td>1.449272</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>4.184599</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>2.377611</td>\n",
       "      <td>-0.895684</td>\n",
       "      <td>-0.697785</td>\n",
       "      <td>-1.016380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>1.493498</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>1.357085</td>\n",
       "      <td>0.702242</td>\n",
       "      <td>1.433107</td>\n",
       "      <td>-1.016380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>-0.840484</td>\n",
       "      <td>0.122505</td>\n",
       "      <td>-0.328637</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>1.238933</td>\n",
       "      <td>-0.596885</td>\n",
       "      <td>1.433107</td>\n",
       "      <td>0.983884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender       age  hypertension  heart_disease  ever_married  \\\n",
       "774  -0.840484 -0.540878     -0.328637      -0.238972      0.723678   \n",
       "2336 -0.840484  1.537723      3.042866      -0.238972      0.723678   \n",
       "2690  1.189791  1.449272     -0.328637       4.184599      0.723678   \n",
       "2430 -0.840484  1.493498     -0.328637      -0.238972      0.723678   \n",
       "3524 -0.840484  0.122505     -0.328637      -0.238972      0.723678   \n",
       "\n",
       "      avg_glucose_level       bmi  smoking_status  residence_type  \n",
       "774           -1.123449  0.468399        1.433107       -1.016380  \n",
       "2336           1.881372 -0.570902       -0.697785        0.983884  \n",
       "2690           2.377611 -0.895684       -0.697785       -1.016380  \n",
       "2430           1.357085  0.702242        1.433107       -1.016380  \n",
       "3524           1.238933 -0.596885        1.433107        0.983884  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stroke\n",
       "774        0\n",
       "2336       0\n",
       "2690       0\n",
       "2430       0\n",
       "3524       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke\n",
       "0         3400\n",
       "1          176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() #imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets continue the Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Logistic Regression on the standardized dataset\n",
    "lr_std = LogisticRegression(solver='lbfgs') #had to add a solver 'lbfgs'\n",
    "lr_std.fit(X_train, y_train.values.ravel()) #had to add .values.ravel() to silence warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_std.predict(X_test)\n",
    "\n",
    "#accuracy of logistic regression, on test set w/scaled features\n",
    "print(lr_std.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# Fit the model on the training data. y_train \n",
    "clf.fit(X_train, y_train) #HAD to add .values.ravel() to silence a warning\n",
    "#of a \"A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\"\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the model with Cross Validation, 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep getting errors so commented out\n",
    "\n",
    "\n",
    "#def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    #result = 0\n",
    "    #nfold = 10\n",
    "    #for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        #clf.fit(x[train], y[train]) # fit\n",
    "        #result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    #return result / nfold # average\n",
    "\n",
    "#clf = LogisticRegression(solver='lbfgs')\n",
    "#score = cv_score(clf, X_train, y_train)\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = ['l1','l2']\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100] \n",
    "\n",
    "log_param_grid = {'penalty': penalty, \n",
    "                  'C': C}\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "grid = GridSearchCV(logreg,log_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = Pipeline(steps = [('scale',StandardScaler()),('LR',LogisticRegression(C=0.1,penalty='l2',random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline.fit(X_train ,y_train)\n",
    "\n",
    "#logreg.fit(X_train_resh,y_train_resh)\n",
    "\n",
    "logreg_tuned_pred = logreg_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,logreg_tuned_pred))\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test,logreg_tuned_pred))\n",
    "print('F1 Score: ',f1_score(y_test,logreg_tuned_pred))\n",
    "#print('ROC-AUC Score: ',roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier() #max_depth=2, random_state=0 add in future\n",
    "clf.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier() #max_depth=2, random_state=0 add in future\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, clf.predict(X_test)) #gets accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]) #roc/auc score tells how \n",
    "#well model is sorting the data.\n",
    "#67% of the time between stroke and non-stroke, it gives the probablility to \n",
    "#the no-stroke case 67% of the time. ## RERAN AND GOT 70%%\n",
    "#if it was 0.50 or 50% which is the low bar, above .5 means your model \n",
    "#is learning something.\n",
    "\n",
    "#RERAN AND GOT 70%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test))) #no stroke, right 94% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot histogram of all predicted probabilites, maybe skewd towards 0\n",
    "#tricky, b/c HUGE imbalance\n",
    "#need to shift the threshold down, there is tradeoff. If you want to be VERY precise, need to set bar high.\n",
    "\n",
    "#need to make a threshold. \n",
    "pd.Series(clf.predict_proba(X_test)[:,1]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps: what the model has learned\n",
    "\n",
    "#feature importances; which variables are important in the decision. what does the model think is important\n",
    "#partial dependence plots; try those\n",
    "\n",
    "\n",
    "#continue on, or fit a new model. \n",
    "#either grid search, gradient boosting, random forest.\n",
    "\n",
    "#full circle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importances\n",
    "#trying this prep data\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "importances = pd.DataFrame(data={'Attribute': X_train.columns, 'Importance': model.coef_[0]})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important feature is age?\n",
    "Interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#pdp, axes = partial_dependence(clf, X, [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X, y)\n",
    "features = [0, 1]\n",
    "plot_partial_dependence(clf, X, features, kind='individual') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(clf, X, features, kind='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 'Name', 'state', and 'Region' columns from the train/test data into \n",
    "#names_train and names_test\n",
    "#Then drop those columns from `X_train` and `X_test`. Use 'inplace=True'\n",
    "\n",
    "#I am saving these columns from the train/test data into stroke_factors_list, and then into\n",
    "#factors_train and factors_test\n",
    "#bmi, hypertension, avg_glucose_level\n",
    "\n",
    "stroke_factors_list = ['bmi', 'hypertension', 'avg_glucose_level']\n",
    "factors_train = X_train[stroke_factors_list]\n",
    "factors_test = X_test[stroke_factors_list]\n",
    "X_train.drop(columns=stroke_factors_list, inplace=True)\n",
    "X_test.drop(columns=stroke_factors_list, inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the `dtypes` attribute of `X_train` to verify all features are numeric\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES KEEP HERE\n",
    "\n",
    "\n",
    "#gradent boost but jeff rec - Random forest! \n",
    "# put logistic regression in as well, simplistic binary classification\n",
    "#now fitting models, predict on test ,look at logreg for height and weight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
